# MySQL深度探索

[TOC]



## 1.基础架构：查询语句的执行过程



```sql
select * from student where id = '1'
```



![查询](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

如上图所示，MySQL大体分为Server层和存储引擎层。

5.5.5版本后默认使用InnoDB引擎，也可手动选择存储引擎。

目前已不存在查询缓存。



#### 连接器

负责跟客户端建立连接、获取权限、维持和管理连接

当用户建立连接后，即使被管理员修改了权限，

也不会影响已存在权限，重连才会生效。

```sql
show processlist
```

查看当前所有的连接及状态



当客户端建立连接后如果太长时间没动静，连接器会自动断开。

wait_timeout 控制，默认空闲时间为8小时。



长连接：连接成功后，用户的持续请求一直使用这一个连接。

短连接：每次执行完很少的请求就断开，下次查询重新创建。



全部使用长连接的话，有时占用内存增长特别快，

因为MySQL在执行过程中使用的内存是管理在连接对象里面，

这些资源在连接断开才会释放。

所以过多的长连接导致内存占用太大，

被系统强行杀掉（OOM），也就是MySQL异常重启。



解决方案：

​	1.定期断开长连接，或者判断执行一个占用内存大的查询后断开

​	2.MySQL5.7之后，可以在比较大的查询之后，执行mysql_reset_connection来初始化资源



#### 查询缓存

建立连接后开始正式执行select语句

MySQL会先去缓存里查找近期是否有相同执行语句。

效率虽高，但大部分情况却是弊大于利：

当表更新时，查询缓存即失效，

除非是一张基本不动的静态表，如系统配置，

否则使用查询缓存的命中率非常低。

query_cache_type=DEMAND

按需查找，不使用查询缓存。

**注：MySQL8.0之后直接将查询缓存模块删除了**



#### 分析器

1.词法分析：识别出语句中的字符串分别代表什么

2语法分析：判断上面分析出的关键词是否符合MySQL语法



#### 优化器

表里存在多个索引的时，判断使用哪个索引，

或者多表关联时决定各个表的连接顺序。



#### 执行器

先判断是否有该表的查询权限，没有的话返回：ERROR 1142(42000)···

执行流程：

​	1.调用InnoDB引擎接口取到表的id行，判断是否符合条件，符合条件放入结果集

​	2.调用引擎接口取“下一行”，重复操作

​	3.将符合条件的结果集返回客户端

数据库慢查询日志中 rows_examined 字段，表示语句执行扫描了多少行。



## 2.日志系统：更新语句是如何执行的



```sql
update student set age=age+1 where ID=2
```

更新语句同查询一样，也会走一遍顶部图片的流程。

与查询流程不一样的是，更新操作涉及两个重要的日志模块：

redo log（重做日志）和binlog（归档日志）。

#### redo log：

如果每次更新操作都需要写进磁盘，磁盘寻找记录，随后更新，

那么整个IO成本、查找成本都很高。

**WAL：Write-Ahead Logging**（先写日志，再写磁盘）

当一条记录需要更新时，InnoDB引擎会把记录写进redo log，

并更新内存这时更新完成。

同时，引擎会在空闲的时候将更新写进磁盘。

如果更新操作较多，则先更新部分数据，腾出地方。

有了redo log，InnoDB就可以保证数据发生异常重启，

但之前记录的数据不会丢失（crash-safe）。

> redo log 不是记录数据页“更新之后的状态”，而是记录这个页“做了什么改动”

#### binlog：

Server层的日志，不具备crash-safe功能。

binlog有两种模式：

statement格式的话是记录sql语句，

row格式会记录行内容（两条），更新前和后

#### 两种日志的区别

1.redo log 是InndoDB引擎特有的，binlog是MySQL的Server层实现，所有引擎都可用

2.redo log是物理日志，记录“在某个数据页上做了什么修改”；

​	binlog是逻辑日志，记录这个语句的原始逻辑

3.redo log 是循环写的，空间固定，binlog是可以追加写入的



#### 更新操作内部执行流程

1.执行器先找引擎取 ID=2。ID是主键，引擎直接用树搜索这一行。

2.执行器拿到行数据，重新赋值，调用引擎接口将新行数据写入。

3.引擎将新行数据更新到内存中，同时记录redo log。

​	此时redo log 处于prepare状态，然后告知执行器执行完成，随后提交事物。

4.执行器生成这个操作的binlog并写入磁盘。

5.执行器调用引擎的提交事物接口，redo log改成提交（commit）状态，更新完成

![image-20181211133910036](/Users/yangbo/Desktop/mysql01.png)



#### 两阶段提交

redo log的写入拆成了两个步骤：prepare 和commit，

是为了让两份日志之间的逻辑一致。

两阶段提交是跨系统维持数据逻辑一致性时常用的方案。



## 事务隔离



简单说,事务就是保证一组数据库操作,要么全成功,要么全失败。

MySQL的事物支持是在引擎层实现的。

MySQL是一个支持多引擎的系统,原生MyISAM不支持事物。



#### 隔离性与隔离级别

ACID（Atomicity,Consistency,lsolation,Durability）

当数据库多个事物同时执行的时候，

可能会出现脏读，不可重复读，幻读的问题，

由此产生“隔离级别”的概念。

正常情况下，隔离级别越高，效率越低。

SQL标准事务隔离级别：

读未提交，读已提交，可重复读，串行化。

- 读未提交（read uncommitted）：一个事物还没提交时，他做的变更就能被别的事物看到
- 读已提交（read committed）：一个事物提交之后，他的变更才会被其他事物看到
- 可重复读（repeatable read）：一个事物执行过程中看到的数据，总是跟这个事物在启动时看到的数据是一致的。
- 串行化（serializable）：对于同一行记录，读写都会加锁，当出现读写锁冲突的时候，后访问的事物必须等前一个事物执行完成才会继续执行。

在实现上，数据库会创建一个视图，访问的时候以视图结果为准。

可重复读时，视图是在事物启动时创建的，整个事物存在期间都用这个视图。

读已提交时，视图是在每个SQL语句开始执行的时候创建的。

读未提交时直接返回记录上的最新值，没有视图概念。

串行化时直接用加锁的方式来避免并行访问。

**Oracle数据库默认隔离级别是”读已提交“**

当Oracle迁移MySQL时为保证隔离级别一致，故修改为读已提交

```sql
mysql> show variables like 'transaction_isolation';

+-----------------------+----------------+

| Variable_name | Value |

+-----------------------+----------------+

| transaction_isolation | READ-COMMITTED |

+-----------------------+----------------+
```



#### 事务隔离的实现

在MySQL中，每条记录在更新的时候都会同时记录一条回滚操作。

记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从1按顺序修改成2，3，4，

在回滚日志里就会有如下记录。





![image-20181214160942410](/Users/yangbo/Desktop/mysql02.png)

当前值是4，不同时刻启动事务就会有不同的read-view。

在视图A、B、C里面，记录的值分别是1、2、4，

同一条记录在系统中可能存在多个版本，即数据库的多版本并发控制（MVCC）。

对于read-view A，要得到1，必须将当前的值依次执行途中所有回滚操作得到。

同时，当有另一个事物将4改为5，这个事物与之前的视图也不会冲突。

**那么，回滚日志什么时候删除？**

在不需要的时候删除，系统会判断，当没有事物需要这些回滚日志时就被删除。

**什么时候才算真正的不需要？**

当系统里没有比这个回滚日志更早的read-view的时候。

**因此，我们尽量不要使用长事物**

> 长事物：长时间未提交的事物

> 在MySQL5.5及以前的版本，回滚日志是跟数据字典一起放在ibadata文件里，
>
> 即使长事物最终提交，回滚段被清理，文件也不会变小。
>
> 除了对回滚段的影响，长事物还占用锁资源，也可能拖垮整个库



#### 事务启动方式

1. 显式启动事务语句，begin或start transaction。提交语句commit，回滚语句rollback。
2. set autocommit=0，这个命令会将当前线程自动提交关闭。意味着如果执行一个select语句，这个事务就启动了，而且不会自动提交。这个事物持续存在直到你主动执行commit或rollback，或断开连接。

有些客户端连接框架会默认连接成功后先执行一个set autocommit=0。

导致接下来的查询都在事物中，如果是长连接，就会导致意外的长事务。

因此，建议总是使用set autocommit=1来显式语句启动事务。

在autocommit为1的情况下，用begin显示启动的事务，如果执行commit则提交事务。

如果执行commit work and chain，则是提交事务并自动启动下一个事务，省去了再次执行begin语句的开销。

同时带来的好处是从程序开发的角度明确的知道每个语句是否在事务中。

**用于查询持续时间超过60秒的事务**

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```



## 索引



索引是数据库最重要的概念之一。

他的出现就是为提高查询效率，类似书的目录。

#### 索引常见模型

索引的实现方式有多种，引入索引模型的概念。

用于提高读写效率的数据结构很多，包括哈希表，有序数组和搜索树等。

哈希表是一种以键-值（key-value）存储的数据结构，

哈希的思路很简单，把值放入数组，用一个哈希函数把key换算成一个确定位置，然后value放入数组的这个位置。

当多个key值经过哈希换算，会出现同一个值的情况（哈希碰撞），

处理这种情况的一种方法就是拉出一个链表。

**哈希表这种数据结构适用于只有等值查询的场景**，比如Memcached及其他NoSQL引擎。

有序数组在等值查询和范围查询场景中性能更优秀。

它的查询效率高，但是更新的话需要挪动后面所有数据，成本太高。

**有序数组只适用于静态存储引擎**

二叉搜索树的特点：每个节点的左儿子小于父节点，父节点又小于右儿子。

二叉树是搜索效率最高的，但实际上大多数数据库存储并不使用二叉树。

因为索引不止存在内存中，还要写到磁盘上。

为了使查询尽量少的读磁盘，就必须让查询尽量少的访问数据块。

因此不应该使用二叉树，而用“N叉树”，“N”取决于数据块的大小。

以InnoDB的一个整数字段索引为例，这个N差不多是1200。

当树高是4的时候，可以存储1200的3次方个值，17亿。

考虑到树根数据块总是在内存中，一个十亿行的表上的整数索引最多只需要访问3次磁盘。

其实，树的第二层也有很大概率在内存中，那么访问磁盘的次数就更少了。

N叉树由于读写上性能的优点以及适配磁盘的访问模式，被广泛应用在数据库引擎中。

数据库底层存储的核心就是基于数据模型的。

当遇到新数据库时需要先关注它的数据模型，才能从理论上分析它的适用场景。

































